# -*- coding: utf-8 -*-
"""soumitra1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SWkHP0fYKE_N1yjZdWrZgtYDsf_jix8d
"""

from nltk.util import bigrams,trigrams,ngrams
import nltk

string="The best and most beautiful thing in the worls is watching the sunrise. It is a beauty of nature."

from nltk import word_tokenize
nltk.download('punkt')

quote=nltk.word_tokenize(string)

quote_bigrams=list(nltk.bigrams(quote))

quote_bigrams

quote_ngrams=list(nltk.ngrams(quote,4))



quote_ngrams

sent="Kashmir is a natural beauty"

sent_token=word_tokenize(sent)
nltk.download('averaged_perceptron_tagger')

for token in sent_token:
  print(nltk.pos_tag([token]))

from nltk import ne_chunk

NE_sent="The US President stays in WhiteHouse"
tkn=word_tokenize(NE_sent)
nltk.download('maxent_ne_chunker')

nltk.download('words')

NE_tag=nltk.pos_tag(tkn)

NE_NER=ne_chunk(NE_tag)

print(NE_NER)

#model.save("name.h5")
 #to download model from colab
 #from google.colab import files
 #files.download("name.h5")



"""
Feature Extraction using pipeline Building mechanism
1.tokenization
2.vectorizer
3.tranformer
4.model training
types of vectorizer-
1.Count
2.TF(term frequency)-IDF(inverse document frequency)
"""

from sklearn.feature_extraction.text import CountVectorizer

text=["the quick brown fox jumps over the lazy dog."]
vectorizer=CountVectorizer()
vectorizer.fit(text)

print(vectorizer.vocabulary_)

vector=vectorizer.transform(text)
print(vector.toarray())

from sklearn.feature_extraction.text import TfidfVectorizer

text=["the quick brown fox jumps over the lazy dog. The dog is so lazy that it does not see the brown fox"]
vectorizer=TfidfVectorizer()
vectorizer.fit(text)

print(vectorizer.vocabulary_)

vector=vectorizer.transform(text)
print(vector.toarray())

#text classification problem
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_20newsgroups
data=fetch_20newsgroups()
data.target_names

categories=['alt.atheism',
 'comp.graphics',
 'comp.os.ms-windows.misc',
 'comp.sys.ibm.pc.hardware',
 'comp.sys.mac.hardware',
 'comp.windows.x',
 'misc.forsale',
 'rec.autos',
 'rec.motorcycles',
 'rec.sport.baseball',
 'rec.sport.hockey',
 'sci.crypt',
 'sci.electronics',
 'sci.med',
 'sci.space',
 'soc.religion.christian',
 'talk.politics.guns',
 'talk.politics.mideast',
 'talk.politics.misc',
 'talk.religion.misc']

train=fetch_20newsgroups(subset="train",categories=categories)
test=fetch_20newsgroups(subset="test",categories=categories)
print(train.data[5])

print(len(train.data))

print(len(test.data))

from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline

model=make_pipeline(TfidfVectorizer(),MultinomialNB())
model.fit(train.data,train.target)
labels=model.predict(test.data)

def predict_category(s,train=train,model=model):
  pred=model.predict([s])
  return train.target_names[pred[0]]

predict_category("the US has thousands of people killed by terrorists from all over the world.")

predict_category("")

